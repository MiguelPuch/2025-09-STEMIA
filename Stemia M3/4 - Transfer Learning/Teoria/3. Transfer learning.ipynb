{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes preentrenadas\n",
    "\n",
    "Entrenar modelos tan grandes resulta costoso y podemos beneficiarnos de la estructura de los modelos existente de forma que solo ajustemos los parámetros finales de cara a la tarea en cuestión que queramos resolver.\n",
    "\n",
    "![imagen](https://www.researchgate.net/publication/336874848/figure/fig1/AS:819325225144320@1572353764073/Illustrations-of-transfer-learning-a-neural-network-is-pretrained-on-ImageNet-and.png)\n",
    "\n",
    "Estas son las arquitecturas de redes neuronales más utilizadas en la comunidad. Para más detalle sobre el funcionamiento de cada red, consultar el [Hands on Machine Learning for Python](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch14.html#cnn_chapter).\n",
    "* VGG-16\n",
    "* VGG-19\n",
    "* Inception V3\n",
    "* XCeption\n",
    "* ResNet-50\n",
    "\n",
    "Las redes se pueden incorporar entrenadas, o sin entrenar.\n",
    "\n",
    "## ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "\n",
    "base_model = ResNet50V2(include_top= True, input_shape=(224, 224, 3), weights='imagenet', classifier_activation= 'softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos algunas imagenes desde local, para ver qué tal funciona la red ResNet50V2 ya entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "\n",
    "def read_data(path):\n",
    "    X = []\n",
    "    for file in os.listdir(path):\n",
    "        image = imread(path + '/' + file)\n",
    "        smallimage = cv2.resize(image, (224,224))\n",
    "        print(path + '/' + file)\n",
    "\n",
    "        X.append(smallimage)\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "\n",
    "X_test = read_data('data/muestras')\n",
    "\n",
    "#Preprocesar las imágenes tal y como entran en el model\n",
    "X_test = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que tenemos 8 predicciones para nuestras imágenes. Pero cada una tiene 1000 potenciales categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos recurrir a las categorías con las que fue entrenada la red original para saber qué significan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import decode_predictions\n",
    "\n",
    "decodes = decode_predictions(preds, top=3)\n",
    "decodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16\n",
    "En este caso vamos a importar la red VGG16, que utilizaremos como red preentrenada y completaremos con una fully connected layer que entrenaremos para nuestro ejercicio base de **Perros y Gatos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IM_SIZE=32\n",
    "\n",
    "TRAIN_PATH = \"data/dogsandcats/train\"\n",
    "filenames = os.listdir(TRAIN_PATH)\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    categories.append(category)\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    'filenames': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "\n",
    "train_df, validate_df = train_test_split(df,\n",
    "                                         test_size=0.20,\n",
    "                                         random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluimos el generador para incorporar las variaciones necesarias para que aprenda gatos y perros en cualquier pose, zoom, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    TRAIN_PATH,\n",
    "                                                    x_col='filenames',\n",
    "                                                    y_col='category',\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (IM_SIZE, IM_SIZE))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df,\n",
    "                                                              TRAIN_PATH,\n",
    "                                                              x_col='filenames',\n",
    "                                                              y_col='category',\n",
    "                                                              batch_size = 20,\n",
    "                                                              class_mode = 'binary',\n",
    "                                                              target_size = (IM_SIZE, IM_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape=(IM_SIZE,IM_SIZE,3),\n",
    "                    include_top=False, # No añadimos la parte del clasificador\n",
    "                    weights = 'imagenet'\n",
    "                )\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nos toca añadir el modelo de clasificación que funcionará sobre las características identificadas clave por la red VGG16 (vectores de 512 características)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.25\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "    \n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgghist = model.fit(train_generator,\n",
    "                    validation_data = validation_generator,\n",
    "                    batch_size = 128,\n",
    "                    epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(vgghist.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(vgghist.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, 5, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(vgghist.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(vgghist.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, 5, 1))\n",
    "\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hubs de modelos\n",
    "\n",
    "Basados en este principio han prolifero los sitios donde la gente cuelga sus modelos, siendo uno de los más habituales HuggingFace: https://huggingface.co/models\n",
    "\n",
    "![](../assets/images/huggingface.png)\n",
    "\n",
    "Gracias a estos repositorios, podemos acceder a modelos entrenados con grandes volúmenes de datos y posteriormente especializarlos para la tarea que nos convenga a nosotros si esta fuera más específica o diferente de la tarea original. Un poco como el caso de los perros y gatos. Sin duda un ahorro de tiempo y costes relevante.\n",
    "\n",
    "Podemos ver como ejemplo la red que hemos importado anteriormente, ResNet50, con la información de detalle y ejemplos que muestra Microsoft: https://huggingface.co/microsoft/resnet-50\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
